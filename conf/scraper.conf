# This is the configuration file for NewsLookout web scraping application
# It is divided up into multiple sections.

[installation]
# this section lists the file and directory locations

# a previously declared variable can be re-used in subsequent variables
# for example, see the use of the 'prefix' variable declared below:
prefix = C:\Users\SandeepSandhu\Documents\ps\src\web_scrape_projs\scraper_py

# location of the log file:
log_file = %(prefix)s\logs\scraper.log

# this is the data directory where the data files will be saved:
data_dir = C:\Users\SandeepSandhu\Documents\datasets\web_scraped_data

# location of the plugins
plugins_dir = %(prefix)s\plugins

# if a pid file exists, the applicaiton will not launch
# this is to prevent multiple instances launched on the same machine
pid_file = %(prefix)s\logs\scraper.pid

completed_urls_datafile = %(data_dir)s\completed_urls.json

cookie_file=%(data_dir)s\cookies.txt


[operation]
# time in seconds to wait for when retrieving a page:
fetch_timeout = 300

# number of times to retry connecting if failed
retry_count = 5

# the fixed number of seconds to wait between web fetches, this
# fixed time is added to the random time to determine the total wait time
# between two web fetches to the same URL 
retry_wait_sec = 3

# minimum number of seconds to wait when calculating the random wait time
retry_wait_rand_min_sec = 2

# maximum number of seconds to wait when calculating the random wait time
retry_wait_rand_max_sec = 5

# should raw html be saved as compressed bzipped files?
save_html=True

# the number of worker threads to use for web scraping:
worker_threads = 4

# proxy configuration paramters:
# proxy_url_http=127.0.0.1:8080
# proxy_url_https=127.0.0.1:8080
proxy_url_http=""
proxy_url_https=""
proxy_user=""
proxy_password=""

# the user agent to use for the web scraper's HTTP(S) GET requests:
user_agent="Mozilla/5.0 (compatible; Googlebot/2.1; +http://www.google.com/bot.html)"


[logging]
# log levels can be one of (starting from less verbosity to full verbosity): ERROR, WARN, INFO, or DEBUG
# log_level=DEBUG
log_level=INFO
# log_level=WARN
# log_level=ERROR



[plugins]
# put names of all modules to be enabled here, separated by commas:
enabled=mod_en_in_ecotimes,mod_en_in_inexp_business,mod_in_nse

# put config specific to each plugin here:


## end of file ##